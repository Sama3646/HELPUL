{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcWdmzFF6Wy3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#not in scope of this course\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CIFAR10(\"/\", download = True, train = True, transform = T.ToTensor())\n",
        "test_dataset = CIFAR10(\"/\", download = True, train = False, transform = T.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9ypghZR7E1p",
        "outputId": "499b4c93-4a3f-4002-d7b7-15f9b05dd017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 87697272.20it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /cifar-10-python.tar.gz to /\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = bs)\n",
        "test_loader = DataLoader(test_dataset, batch_size = bs)"
      ],
      "metadata": {
        "id": "vPZq_vzw7RNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tasks\n",
        "#1) Create at least 4 layers NN to classify the dataset\n",
        "#2) Train the neural network on train dataset\n",
        "#3) Show the training loss\n",
        "#4) Calculate the accuracy on test set\n",
        "#5) Show a few incorrectly classified samples\n",
        "#6) Calculate class-wise accuracy (implement the function yourself)"
      ],
      "metadata": {
        "id": "NBETITp396AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer4 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer5 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.relu(self.layer4(x))\n",
        "        x = self.layer5(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "m7v3XHperl8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.reshape(-1, input_size)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return (correct / total) * 100"
      ],
      "metadata": {
        "id": "I5XLmSQ2sVKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 3 * 32 * 32 # CIFAR-10 images are 32x32x3 (3 color channels)\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "\n",
        "model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "t5ykmb4Qr915"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.reshape(-1, input_size)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    train_accuracy = calculate_accuracy(train_loader)\n",
        "    test_accuracy = calculate_accuracy(test_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "print('Training finished')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KwdkVQcsF2C",
        "outputId": "84ab42ef-a9f6-4ea3-9dc2-0c0e078f9e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.0337, Training Accuracy: 40.24%, Test Accuracy: 40.01%\n",
            "Epoch [2/10], Loss: 1.9801, Training Accuracy: 43.21%, Test Accuracy: 42.70%\n",
            "Epoch [3/10], Loss: 1.9406, Training Accuracy: 44.51%, Test Accuracy: 43.84%\n",
            "Epoch [4/10], Loss: 1.7289, Training Accuracy: 46.27%, Test Accuracy: 45.53%\n",
            "Epoch [5/10], Loss: 1.6976, Training Accuracy: 47.07%, Test Accuracy: 45.95%\n",
            "Epoch [6/10], Loss: 1.6623, Training Accuracy: 48.39%, Test Accuracy: 47.27%\n",
            "Epoch [7/10], Loss: 1.6235, Training Accuracy: 48.75%, Test Accuracy: 47.14%\n",
            "Epoch [8/10], Loss: 1.6789, Training Accuracy: 49.16%, Test Accuracy: 47.05%\n",
            "Epoch [9/10], Loss: 1.5978, Training Accuracy: 50.17%, Test Accuracy: 46.89%\n",
            "Epoch [10/10], Loss: 1.5871, Training Accuracy: 51.04%, Test Accuracy: 47.82%\n",
            "Training finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_classwise_accuracy(model, data_loader, num_classes):\n",
        "    class_correct = [0] * num_classes\n",
        "    class_total = [0] * num_classes\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.reshape(-1, input_size)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    class_accuracy = []\n",
        "    for i in range(num_classes):\n",
        "        if class_total[i] == 0:\n",
        "            class_accuracy.append(0.0)\n",
        "        else:\n",
        "            class_accuracy.append(100 * class_correct[i] / class_total[i])\n",
        "    return class_accuracy"
      ],
      "metadata": {
        "id": "-o6AeuANs-Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "classwise_accuracy = calculate_classwise_accuracy(model, test_loader, num_classes)\n",
        "for i in range(num_classes):\n",
        "    print(f'Class {i}: {classwise_accuracy[i]:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5_tP84yuVQ0",
        "outputId": "2325d7db-fa89-4622-f2bf-de39a4762f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 51.30%\n",
            "Class 1: 63.90%\n",
            "Class 2: 26.30%\n",
            "Class 3: 43.40%\n",
            "Class 4: 41.90%\n",
            "Class 5: 24.20%\n",
            "Class 6: 55.30%\n",
            "Class 7: 52.70%\n",
            "Class 8: 66.70%\n",
            "Class 9: 52.50%\n"
          ]
        }
      ]
    }
  ]
}